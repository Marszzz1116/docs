import{_ as e,D as p,c as h,I as t,w as n,U as l,m as s,a as i,o as k}from"./chunks/framework.-9Q_U4ls.js";const qs=JSON.parse('{"title":"可用于UOS桌面应用性能自动化工具的调研","description":"","frontmatter":{},"headers":[],"relativePath":"技术文档/技术调研/可用于UOS桌面应用性能自动化工具的调研.md","filePath":"技术文档/技术调研/可用于UOS桌面应用性能自动化工具的调研.md","lastUpdated":1705116614000}'),d={name:"技术文档/技术调研/可用于UOS桌面应用性能自动化工具的调研.md"},r=l("",3),E=l("",14),o=s("p",null,"这里就拿冷启动来举例，整个过程如图2所示：",-1),g=s("p",null,"![image-20210311193848186](可用于UOS桌面应用性能自动化工具的调研.assets/图2 冷启动过程.png)",-1),c=s("p",null,"等我们一次次拍摄完毕后，我们才会使用解帧工具进行分帧操作，然后再一张张图片的找到首尾帧，过程看似比较简单，但是其实是比较繁琐且复杂的。",-1),y=s("p",null,"这种方法的优点就是不会占用系统资源，不会影响测试结果的准确性，可是事实上这种方式可能会导致数据的不稳定性，首先对于拍摄设备来说，每个人使用的手机不同，录制视频的质量不同，拍摄角度、拍摄手法也不同，录制视频时，摄像头会因为屏幕的光线和外界的灯光，使录制出来的视频辨认程度大大降低，实际拍摄效果如图3所示：",-1),_=s("p",null,"![image-20210311194411329](可用于UOS桌面应用性能自动化工具的调研.assets/图3 低辨识度效果.png)",-1),u=s("p",null,"这张图是看图启动时分帧结果中，UI界面出现的第二张图片，从图上可以看到很多细节都不能看见，本着对性能测试的精准性考虑，这张图就不能作为尾帧来使用，因为看图出来时，手机摄像头要重新聚焦屏幕，致使无法确定看图是否界面已经加载完毕，这样就导致分帧出来的结果会存在较大的偏差，不能得到最真实的启动数据，所以我们就需要选择界面很清晰的图片选来使用，清晰的效果如图4所示：",-1),F=s("p",null,"![image-20210311200159058](可用于UOS桌面应用性能自动化工具的调研.assets/图4 高辨识度效果.png)",-1),C=s("p",null,"这种情况我们通过统一的规范要求来进行避免，使用统一的三脚架，统一的拍摄手法，统一的选图标准，来提升测试结果的准确性；我们通过日常实践证明，这确实可以提升性能测试数据的准确性；可是缺点也是很显而易见的，使整个性能测试周期延长，影响项目进度。",-1),A=s("p",null,"其实整个测试过程中，不仅仅是拍摄过程需要大量的时间，数帧也需要大量的时间，性能测试采用的分帧策略是1秒钟的视频分帧成33张图片，一帧图片的误差的时间只有33.3ms，对于准确度毫无疑问是很精准的。对于冷热启动来说，耗时少图片数量也少，一般视频长度也就5秒钟左右，只需要查看一二百多张图片就能完成找帧的工作，但是性能测试中也有很多很耗时的指标，视频长度往往需要十几秒，甚至几十秒，那么图片的基数就会变得很大，那么找帧工作就会很耗时，如图5所示，看图性能测试指标中的加载40MB图片的性能素材目录：",-1),m=s("p",null,"![image-20210312094400713](可用于UOS桌面应用性能自动化工具的调研.assets/图5 看图性能素材.png)",-1),D=s("p",null,"从图上可以很直观的看到目录中的总文件数为4004项，要从这些图片中找到首尾帧，不用想肯定是一件很耗时的事情，而且测试人员通常是每一个指标，拍摄至少7组视频，也就是说一个平台上面相当于就有28000张图片需要进行首尾帧的筛选，可见这个过程是一个很繁琐的工作。",-1),b=s("p",null,"多媒体所有的应用，或多或少都会有比较耗时的指标，整个性能测试测试下来，每个应用在每个平台上所需要查看的图片均在40000张及以上，像文管这种指标繁多的应用，甚至是有十几万张图片需要筛选。",-1),S=s("p",null,"所以纵观整个方案一，优点是精准度较高，但是最明显的缺点就是耗时巨大。",-1),f=s("p",null,"方案二：使用time命令启动应用，直接得到性能数据",-1),x=s("p",null,"Linux本身就提供了time命令，可用于性能测试的启动时间测试，还可以测量内存、I/O等的使用情况。我们可以直接使用命令time来开启应用，比如开启看图测试看图的启动时间，如图6所示：",-1),T=s("p",null,"![image-20210312130549426](../../public/可用于UOS桌面应用性能自动化工具的调研.assets/图6 time命令获取应用启动时间.png)",-1),v=s("p",null,"在图中我们可以清晰的看见三个时间项，分别是real真实时间，user用户时间，sys系统时间，启动时间我们可以理解为用户时间加上系统时间，从图中可知是97毫秒，这个方法可以很快速的获取应用的启动时间，避免了录屏分帧的时间消耗，比方案一节约了不少时间上的消耗。",-1),B=s("p",null,"可是这个数据其实是不真实的，也是不准确的，我们依据方案一中的看图冷启动来看，分帧录屏与time命令之间差距为100ms左右，这对于毫秒级别的速度来说误差已经很大了，通过命令来开启应用，实际上与在桌面双击打开，以及dock栏打开完全是不一样的，我们知道从不同地方去调起应用，都是通过不同的接口，在调用接口之前，桌面或dock栏需要先将自己的程序跑完，然后才会调用接口，跟终端的代码执行时间肯定是不一样的，我们用户真实感受的时间，应该是图7所示的代码执行顺序：",-1),P=s("p",null,"![image-20210318134004406](../../public/可用于UOS桌面应用性能自动化工具的调研.assets/图7 time命令获取启动时间流程.png)",-1),q=s("p",null,"只有从桌面或者dock栏来测试应用的启动时间，才是最贴近用户使用的，而这个time命令最大的缺点就是与用户使用场景是有冲突的，所以只从这一个方面看来就并不是很适用当前的性能测试策略。",-1),V=s("p",null,"其次，这个命令只能单一的启动程序，不能做一些其他较为复杂的操作，可我们的性能指标，不仅仅只是冷热启动，还有各式各样的操作，所以这种测试方法就显得很不实用，不能覆盖所有的测试场景，所以这种方案也不是目前的最优解。我们简单的来看一下文件管理器和相机的性能测试指标，如表2所示：",-1),I=l("",6),U=s("p",null,"这个方法首先需要开发更改代码，在相应的地方增加埋点，然后再进行测试，这个方法其实和方案二比较相似，都是站在计算机的角度去测试时长，并没有站在用户只会使用眼睛感受的角度，此方案还有一个缺点就是性能测试版本与用户使用版本是不一样的，这也导致了测试指标可能是不真实的情况，版本都不是一个版本，又从何处去保证性能是一个性能呢，而且纵观之前的测试数据来说，数帧时间与埋点时间差值也是超过了100ms，所以也是十分不准确的。",-1),O=s("p",null,"其次，计算机执行代码是一行一行执行的，增加了很多个埋点在其中，对性能肯定是有影响的，从根本上就不能保证这个时间的准确性，而且计算机渲染也有时间问题，应用代码执行到了开启的那一行，可是渲染可能只渲染了一个窗口框架出来，这样肯定是有时间差距的，与time命令一样，与用户的感受是背道而驰的。",-1),X=s("p",null,"只是这个方案比time命令好的就是，它可以适应所有的性能指标，需要什么就在固定的位置增加埋点，通过时间差确实可以获得近似真实的性能值，之前测试性能指标确实也用了一段时间这种方法，可是最后之所以没有使用，就是因为使用应用的性能测试版本获得的性能测试结果，与真实用户使用的应用版本的结果偏差较大，所以经过实践，这种方法确实不是最优解，最多也就只能当成参考值。",-1),R=s("p",null,"所以纵观整个方案三，优缺点与方案二类似，可以解决耗时问题，可是对于更加重要的准确度却是力不从心，也不太适合现在的性能测试环境。",-1),N=s("p",null,"总结： 现目前这三种方案，都是各有优劣，方案二和方案三缺点很相似，最主要都是精准度不高。三个方案的优缺点如表3所示：",-1),M=l("",8),K=s("h3",{id:"整体设计",tabindex:"-1"},[i("整体设计 "),s("a",{class:"header-anchor",href:"#整体设计","aria-label":'Permalink to "整体设计"'},"​")],-1),w=s("p",null,"在StagesepX的应用过程中，每个阶段将承担不同任务。我们需要了解每个阶段StagesepX到底做了哪些工作，我们将怎样去运用它。",-1),G=s("h4",{id:"录制测试视频",tabindex:"-1"},[i("录制测试视频 "),s("a",{class:"header-anchor",href:"#录制测试视频","aria-label":'Permalink to "录制测试视频"'},"​")],-1),H=s("p",null,"不管是运用常规的性能测试方法，还是运用自动化去进行冷热启动的性能测试，我们都需要进行视频录制。在日常测试中，我们通常采用外部设备来进行录制。对于我们肉眼来说，我们可以主动判断当前帧的情况，决定其能否作为首帧或尾帧。而对于机器来说，外部设备录制的视频由于光线、清晰度、抖动等因素，会对SSIM值产生严重的影响。因此，我们需要更加稳定的视频。",-1),j=s("p",null,"我们对Linux平台下的视频录制工具做了大量的调研，先后验证了UOS截图录屏、FFmpeg、SimpleScreenRecorder、Guee等工具的录屏效果以及开启工具后是否会对我们应用本身的启动造成影响。调研结果显示：UOS截图录屏因为使用了FFmpeg，在MIPS平台和ARM平台启动录屏功能后，CPU占用分别达到了200%和120%，导致系统卡顿，影响应用本身启动性能；而直接使用FFmpeg，无法在MIPS架构下完成录屏，大量的丢帧导致视频不能正常使用；SimpleScreenRecorder占用大量的资源，对我们应用本身启动产生严重的影响。最后我们采用了UOS商店的第三方录屏软件Guee（在X86架构也可以使用UOS截图录屏，为方便获取实验数据，这里统一使用Guee进行实验验证），该应用在MIPS平台启动录屏后，稳定状态CPU占用约为70%，综合来说对应用的影响最小。",-1),z=s("p",null,"我们在各架构下，选取了4个UOS应用，分别使用外部录屏工具和Guee工具在相同的条件下进行录屏，分帧后对两者的结果进行对比，确保录制的视频能够被我们使用。如图10所示，为对比结果：",-1),$=s("p",null,"![image-20210313140043366](可用于UOS桌面应用性能自动化工具的调研.assets/图10 外部设备与Guee录屏结果对比.png)",-1),L=l("",6),J=l("",8),Q=l("",7),W=s("p",null,"另外，StagesepX记录了应用启动的过程，并以不同的阶段进行展示。同时记录了每一个阶段的变化情况和耗时。我们可以从下图中，看到区间的变化以及耗时情况，如图14所示：",-1),Y=s("p",null,"![image-20201127235349053](可用于UOS桌面应用性能自动化工具的调研.assets/图14 应用启动变化状态及阶段耗时.png)",-1),Z=s("h3",{id:"关键技术",tabindex:"-1"},[i("关键技术 "),s("a",{class:"header-anchor",href:"#关键技术","aria-label":'Permalink to "关键技术"'},"​")],-1),ss=s("h4",{id:"视频预处理",tabindex:"-1"},[i("视频预处理 "),s("a",{class:"header-anchor",href:"#视频预处理","aria-label":'Permalink to "视频预处理"'},"​")],-1),is=s("p",null,"由于拍摄设备的不稳定和不确定性，会出现录制的视频出现帧不稳定的情况，具体表现为每一帧的时长不恒定，我们可以通过以下图片进行简单的理解，如图15所示：",-1),as=s("p",null,"![](/可用于UOS桌面应用性能自动化工具的调研.assets/图15 帧数变化例子.svg)",-1),ts=l("",8),ns=l("",7),ls=l("",5),es=s("h3",{id:"模型训练-1",tabindex:"-1"},[i("模型训练 "),s("a",{class:"header-anchor",href:"#模型训练-1","aria-label":'Permalink to "模型训练"'},"​")],-1),ps=s("p",null,"我们通过分拣好的素材，利用Keras将其训练成测试模型。需要提到的是，在训练过程中，并没有可用的参数。所以我们只要保证模型能训练成功即可。如图18所示：",-1),hs=s("p",null,"![image-20201128013635943](可用于UOS桌面应用性能自动化工具的调研.assets/图18 模型训练结果.png)",-1),ks=l("",12),ds=s("p",null,"根据我们的测试经验，我们需要的数据是：从点击【打开】按钮后，到界面加载结束的时间。",-1),rs=s("p",null,"通过分析结果，我们可以看到，应用加载过程中第一个不稳定阶段为鼠标在桌面移动的阶段。此阶段由于鼠标不断移动，StagesepX认为该阶段不稳定。",-1),Es=s("p",null,"第二个不稳定阶段为dock栏右键点击应用后，右键菜单弹出的过程。这个阶段有较为明显的变化。",-1),os=s("p",null,"第三个不稳定阶段为鼠标点击【打开】按钮后，直到页面加载完成的过程。我们通过截取此阶段详细图来了解一下该过程，如图20、图21所示：",-1),gs=s("p",null,"![image-20201128021601300](可用于UOS桌面应用性能自动化工具的调研.assets/图20 点击启动后的变化过程.png)",-1),cs=s("p",null,"![image-20201128021615033](可用于UOS桌面应用性能自动化工具的调研.assets/图21 应用加载过程.png)",-1),ys=l("",6),_s=s("p",null,"对比传统测试的结果(230ms)，我们发现，通过StagesepX获得的数据，与我们预期的结果仅有一帧(30ms)的差距。这是一个让我们感到惊喜的结果！",-1),us=s("h2",{id:"小结",tabindex:"-1"},[i("小结 "),s("a",{class:"header-anchor",href:"#小结","aria-label":'Permalink to "小结"'},"​")],-1),Fs=s("p",null,"通过StagesepX实现自动化的视频处理，可以很大程度上提高我们的测试效率。目前测试人员完成一个应用的性能测试，需要依次在各个架构进行测试，耗费1-2天的时间。如果使用StagesepX来完成任务，可以多个架构任务并行，这样完成任务大概只需要消耗1/2的时间；同时可以解放更多的人力，投入到其他测试工作中。从测试结果来看，它产出的结果能够满足我们测试人员的需要，解决了我们以下难题：",-1),Cs=s("ul",null,[s("li",null,[s("p",null,"效率低下，投入时间太高。")]),s("li",null,[s("p",null,"重复劳动，获取测试数据。")])],-1),As=s("p",null,"从长远来看，StagesepX具有以下优缺点：",-1),ms=l("",3),Ds=l("",5);function bs(Ss,fs,xs,Ts,vs,Bs){const a=p("center");return k(),h("div",null,[r,t(a,{style:{color:"#C0C0C0"}},{default:n(()=>[i("表1 术语")]),_:1}),E,t(a,{style:{color:"#C0C0C0"}},{default:n(()=>[i("图1 录屏分帧流程")]),_:1}),o,g,t(a,{style:{color:"#C0C0C0"}},{default:n(()=>[i("图2 冷启动过程")]),_:1}),c,y,_,t(a,{style:{color:"#C0C0C0"}},{default:n(()=>[i("图3 低辨识度效果")]),_:1}),u,F,t(a,{style:{color:"#C0C0C0"}},{default:n(()=>[i("图4 高辨识度效果")]),_:1}),C,A,m,t(a,{style:{color:"#C0C0C0"}},{default:n(()=>[i("图5 看图性能素材")]),_:1}),D,b,S,f,x,T,t(a,{style:{color:"#C0C0C0"}},{default:n(()=>[i("图6 time命令获取应用启动时间")]),_:1}),v,B,P,t(a,{style:{color:"#C0C0C0"}},{default:n(()=>[i("图7 time命令获取启动时间流程")]),_:1}),q,V,t(a,{style:{color:"#C0C0C0"}},{default:n(()=>[i("表2 文管和相机性能指标")]),_:1}),I,t(a,{style:{color:"#C0C0C0"}},{default:n(()=>[i("图8 埋点获取启动时间流程")]),_:1}),U,O,X,R,N,t(a,{style:{color:"#C0C0C0"}},{default:n(()=>[i("表3 三种方案优缺点总结")]),_:1}),M,t(a,{style:{color:"#C0C0C0"}},{default:n(()=>[i("图9 StagesepX工作流程")]),_:1}),K,w,G,H,j,z,$,t(a,{style:{color:"#C0C0C0"}},{default:n(()=>[i("图10 外部设备与Guee录屏结果对比")]),_:1}),L,t(a,{style:{color:"#C0C0C0"}},{default:n(()=>[i("图11 StagesepX分类结果")]),_:1}),J,t(a,{style:{color:"#C0C0C0"}},{default:n(()=>[i("图12 模型训练结果")]),_:1}),Q,t(a,{style:{color:"#C0C0C0"}},{default:n(()=>[i("图13 报告中记录的应用启动变化过程")]),_:1}),W,Y,t(a,{style:{color:"#C0C0C0"}},{default:n(()=>[i("图14 应用启动变化状态及阶段耗时")]),_:1}),Z,ss,is,as,t(a,{style:{color:"#C0C0C0"}},{default:n(()=>[i("图15 帧数变化例子")]),_:1}),ts,t(a,{style:{color:"#C0C0C0"}},{default:n(()=>[i("表4 参数及对应说明")]),_:1}),ns,t(a,{style:{color:"#C0C0C0"}},{default:n(()=>[i("图16 分帧结果")]),_:1}),ls,t(a,{style:{color:"#C0C0C0"}},{default:n(()=>[i("图17 分拣后的稳定阶段")]),_:1}),es,ps,hs,t(a,{style:{color:"#C0C0C0"}},{default:n(()=>[i("图18 模型训练结果")]),_:1}),ks,t(a,{style:{color:"#C0C0C0"}},{default:n(()=>[i("图19 应用启动变化过程")]),_:1}),ds,rs,Es,os,gs,t(a,{style:{color:"#C0C0C0"}},{default:n(()=>[i("图20 点击启动后的变化过程")]),_:1}),cs,t(a,{style:{color:"#C0C0C0"}},{default:n(()=>[i("图21 应用加载过程")]),_:1}),ys,t(a,{style:{color:"#C0C0C0"}},{default:n(()=>[i("图22 测试结果")]),_:1}),_s,us,Fs,Cs,As,t(a,{style:{color:"#C0C0C0"}},{default:n(()=>[i("表5 StagesepX优缺点")]),_:1}),ms,t(a,{style:{color:"#C0C0C0"}},{default:n(()=>[i("图23 采集卡工作流程")]),_:1}),Ds])}const Vs=e(d,[["render",bs]]);export{qs as __pageData,Vs as default};
